{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool as gap\n",
    "from torch_geometric.utils import subgraph\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from rdkit import Chem\n",
    "import itertools\n",
    "from model import DumplingGNN\n",
    "import csv\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, matthews_corrcoef,\n",
    "    precision_recall_curve, auc\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "supplier = Chem.SDMolSupplier('train_chembl.sdf', removeHs=False)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "def mol_to_graph_with_coords(mol):\n",
    "    # Extracting atomic signatures\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_feature = [\n",
    "            atom.GetAtomicNum(),  \n",
    "            atom.GetDegree(),  \n",
    "            atom.GetTotalNumHs(),  \n",
    "            atom.GetImplicitValence(),  \n",
    "            atom.GetIsAromatic(),  \n",
    "        ] + list(mol.GetConformer().GetAtomPosition(atom.GetIdx()))  \n",
    "        atom_features.append(atom_feature)\n",
    "\n",
    "    # Extract Side Index\n",
    "    edge_indices = []\n",
    "    for bond in mol.GetBonds():\n",
    "        start_atom = bond.GetBeginAtomIdx()\n",
    "        end_atom = bond.GetEndAtomIdx()\n",
    "        edge_indices.append([start_atom, end_atom])\n",
    "        edge_indices.append([end_atom, start_atom])\n",
    "\n",
    "    # # Convert features and indices to PyTorch tensors\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    # Get labels\n",
    "    label = mol.GetProp(\"label\")\n",
    "    y = torch.tensor([float(label)], dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mol in supplier:\n",
    "    if mol is not None:\n",
    "        data = mol_to_graph_with_coords(mol)\n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "train_data_list, test_data_list = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data_list, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data_list, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the model\n",
    "model = DumplingGNN(hidden_channels=32)\n",
    "model_name = model.__class__.__name__\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "tensor([[100,   0],\n",
      "        [ 77,   0]], dtype=torch.int32)\n",
      "Epoch: 1, Loss: 0.6665, Test Accuracy: 0.5650, AUC: 0.5745\n",
      "Now Highest Test Accuracy: 0.5650, Highest AUC: 0.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22102\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "tensor([[100,   0],\n",
      "        [ 77,   0]], dtype=torch.int32)\n",
      "Epoch: 2, Loss: 0.6598, Test Accuracy: 0.5650, AUC: 0.5875\n",
      "Now Highest Test Accuracy: 0.5650, Highest AUC: 0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22102\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m     40\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(train_loader)\n\u001b[1;32m---> 41\u001b[0m     all_preds, all_labels, pred_labels\u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(all_labels, pred_labels)\n\u001b[0;32m     44\u001b[0m     acc \u001b[38;5;241m=\u001b[39m accuracy_score(all_labels, pred_labels)\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m---> 10\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m         probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(out)  \n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# print(probs)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\0ADC\\new\\writing\\MDPI\\code-realease\\model.py:203\u001b[0m, in \u001b[0;36mDumplingGNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    200\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39melu(x)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# 第二个GAT层\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgat2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# 第三个GAT层\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:325\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[1;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe usage of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimultaneously is currently not yet supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseTensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m form\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# edge_updater_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_updater\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                          \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: PairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m    329\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39m(x_l, x_r), alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_edge_updater_1x8gvw75.py:145\u001b[0m, in \u001b[0;36medge_updater\u001b[1;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21medge_updater\u001b[39m(\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    137\u001b[0m     edge_index: Union[Tensor, SparseTensor],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     size: Size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    143\u001b[0m     mutable_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(edge_index, size)\n\u001b[1;32m--> 145\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_collect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# Begin Edge Update Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\torch_geometric.nn.conv.gatv2_conv_GATv2Conv_edge_updater_1x8gvw75.py:91\u001b[0m, in \u001b[0;36medge_collect\u001b[1;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_size(size, \u001b[38;5;241m0\u001b[39m, _x_0)\n\u001b[1;32m---> 91\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:267\u001b[0m, in \u001b[0;36mMessagePassing._index_select\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim, index)\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index_select_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:271\u001b[0m, in \u001b[0;36mMessagePassing._index_select_safe\u001b[1;34m(self, src, index)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_index_select_safe\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: Tensor, index: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m index\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data)\n",
    "            probs = torch.sigmoid(out)  \n",
    "            # print(probs)\n",
    "            all_preds.extend(probs[:, 1].tolist()) \n",
    "            all_labels.extend(data.y.tolist()) \n",
    "\n",
    "            result = out.argmax(dim=1)  \n",
    "            # print(result)\n",
    "            pred_labels.extend(result.tolist())\n",
    "            correct += (result == data.y).sum().item()  \n",
    "            total += data.y.size(0)\n",
    "    \n",
    "    # Print CM Matrix\n",
    "    print('Confusion Matrix:')\n",
    "    table = torch.zeros(2, 2, dtype=torch.int32)\n",
    "    for i in range(len(all_labels)):\n",
    "        table[int(all_labels[i]), int(pred_labels[i] > 0.5)] += 1\n",
    "    print(table)\n",
    "\n",
    "    return all_preds, all_labels, pred_labels\n",
    "  \n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "auc_scores = []\n",
    "higest_accuracy = 0\n",
    "higest_auc = 0\n",
    "csv_file = f'{model_name}.csv'\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    train_loss = train(train_loader)\n",
    "    all_preds, all_labels, pred_labels= test(test_loader)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, pred_labels)\n",
    "    acc = accuracy_score(all_labels, pred_labels)\n",
    "    se = recall_score(all_labels, pred_labels)  # Sensitivity / Recall\n",
    "    sp = cm[0, 0] / (cm[0, 0] + cm[0, 1])  # Specificity\n",
    "    mcc = matthews_corrcoef(all_labels, pred_labels)\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, pred_labels)\n",
    "    ba = (se + sp) / 2  # Balanced Accuracy\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_preds)\n",
    "    prauc = auc(recall, precision)  # PR AUC\n",
    "    ppv = precision_score(all_labels, pred_labels)  # Positive Predictive Value\n",
    "    npv = cm[0, 0] / (cm[0, 0] + cm[1, 0])  # Negative Predictive Value\n",
    "\n",
    "\n",
    "    # print(f\"Accuracy: {acc}\")\n",
    "    # print(f\"Sensitivity (Recall): {se}\")\n",
    "    # print(f\"Specificity: {sp}\")\n",
    "    # print(f\"MCC: {mcc}\")\n",
    "    # print(f\"AUC: {auc_score}\")\n",
    "    # print(f\"F1 Score: {f1}\")\n",
    "    # print(f\"Balanced Accuracy: {ba}\")\n",
    "    # print(f\"PRAUC: {prauc}\")\n",
    "    # print(f\"PPV: {ppv}\")\n",
    "    # print(f\"NPV: {npv}\")\n",
    "\n",
    "    headers = ['epoch', 'Loss', 'Accuracy', 'Sensitivity (Recall)', 'Specificity', 'MCC', 'AUC', 'F1 Score', 'Balanced Accuracy', 'PRAUC', 'PPV', 'NPV']\n",
    "    data = [epoch+1, train_loss, acc, se, sp, mcc, auc_score, f1, ba, prauc, ppv, npv]\n",
    "\n",
    "\n",
    "    with open(csv_file, mode='a', newline='') as file:  \n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(headers)\n",
    "        writer.writerow(data)\n",
    "        train_losses.append(train_loss)\n",
    "        test_accuracies.append(acc)\n",
    "    if acc > higest_accuracy:\n",
    "        higest_accuracy = acc\n",
    "        torch.save(model.state_dict(), f'saved_best_acc{model_name}.pth')\n",
    "    if auc_score > higest_auc:\n",
    "        higest_auc = auc_score\n",
    "        torch.save(model.state_dict(), f'saved_best_auc{model_name}.pth')\n",
    "    #scheduler.step(train_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Loss: {train_loss:.4f}, Test Accuracy: {acc:.4f}, AUC: {auc_score:.4f}')\n",
    "    print(f\"Now Highest Test Accuracy: {higest_accuracy:.4f}, Highest AUC: {higest_auc:.4f}\")\n",
    "    \n",
    "    #plt.figure(figsize=(10, 5))\n",
    "print('Highest Test Accuracy:', higest_accuracy)\n",
    "print('Highest AUC:', higest_auc)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
